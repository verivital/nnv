{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100",
   "authorship_tag": "ABX9TyMr9EkccUbjhADX4IUnCy0s"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5y8epsA_G30",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756449532221,
     "user_tz": 300,
     "elapsed": 13459,
     "user": {
      "displayName": "Sam Sasaki",
      "userId": "14262134318359374727"
     }
    },
    "outputId": "59fea1bd-190a-4bfa-f6a3-14bcdd1bc344"
   },
   "outputs": [],
   "source": "# Configuration - Docker container paths\n# When running in NNV Docker container, data is at /nnv/code/nnv/examples/Submission/FORMALISE2025/data\nBASE_DIR = \"/nnv/code/nnv/examples/Submission/FORMALISE2025\"\nDATA_DIR = f\"{BASE_DIR}/data\"\nMODELS_DIR = f\"{BASE_DIR}/models\"\n\n# Frame count configuration\nMAX_FRAMES = 16  # Options: 8, 16, 32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download dataset"
   ],
   "metadata": {
    "id": "2riXhrLLj4aZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! wget https://www.csc.kth.se/cvap/actions/walking.zip\n",
    "! wget https://www.csc.kth.se/cvap/actions/jogging.zip\n",
    "! wget https://www.csc.kth.se/cvap/actions/running.zip\n",
    "! wget https://www.csc.kth.se/cvap/actions/boxing.zip\n",
    "! wget https://www.csc.kth.se/cvap/actions/handwaving.zip\n",
    "! wget https://www.csc.kth.se/cvap/actions/handclapping.zip"
   ],
   "metadata": {
    "id": "Uc02DIInBTV7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! wget https://www.csc.kth.se/cvap/actions/00sequences.txt"
   ],
   "metadata": {
    "id": "U7xY027Qf_Tr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756449564770,
     "user_tz": 300,
     "elapsed": 999,
     "user": {
      "displayName": "Sam Sasaki",
      "userId": "14262134318359374727"
     }
    },
    "outputId": "7595d48e-dbd9-47b5-eb48-d7be80d72b11"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2025-08-29 06:39:23--  https://www.csc.kth.se/cvap/actions/00sequences.txt\n",
      "Resolving www.csc.kth.se (www.csc.kth.se)... 130.237.28.41, 2001:6b0:1:11c2::82ed:1c29\n",
      "Connecting to www.csc.kth.se (www.csc.kth.se)|130.237.28.41|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 38292 (37K) [text/plain]\n",
      "Saving to: ‘00sequences.txt’\n",
      "\n",
      "00sequences.txt       0%[                    ]       0  --.-KB/s               ^C\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! mkdir data\n",
    "! unzip -qq walking.zip -d data\n",
    "! unzip -qq jogging.zip -d data\n",
    "! unzip -qq running.zip -d data\n",
    "! unzip -qq boxing.zip -d data\n",
    "! unzip -qq handwaving.zip -d data\n",
    "! unzip -qq handclapping.zip -d data"
   ],
   "metadata": {
    "id": "2RBOtG-uj8EE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! mkdir data/train\n",
    "! mkdir data/val\n",
    "! mkdir data/test"
   ],
   "metadata": {
    "id": "YKV21o3ukUD6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# split the videos into train/val/test by people ID as described by 00sequences.txt\n",
    "train_samples = [11, 12, 13, 14, 15, 16, 17, 18]\n",
    "val_samples = [19, 20, 21, 23, 24, 25, 1, 4]\n",
    "test_samples = [22, 2, 3, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# task names\n",
    "tasks = ['boxing', 'handclapping', 'handwaving', 'jogging', 'running', 'walking']\n",
    "\n",
    "# various setting labels (1-4)\n",
    "settings = [1, 2, 3, 4]\n",
    "\n",
    "train_samples_names = []\n",
    "val_samples_names = []\n",
    "test_samples_names = []\n",
    "\n",
    "for task in tasks:\n",
    "  for setting in settings:\n",
    "    for sample in train_samples:\n",
    "      sample_str = str(sample).zfill(2) # add 0 to front if necessary\n",
    "      train_samples_names.append(f'person{sample_str}_{task}_d{setting}')\n",
    "\n",
    "    for sample in val_samples:\n",
    "      sample_str = str(sample).zfill(2) # add 0 to front if necessary\n",
    "      val_samples_names.append(f'person{sample_str}_{task}_d{setting}')\n",
    "\n",
    "    for sample in test_samples:\n",
    "      sample_str = str(sample).zfill(2) # add 0 to front if necessary\n",
    "      test_samples_names.append(f'person{sample_str}_{task}_d{setting}')\n",
    "\n",
    "print(train_samples_names)\n",
    "print(val_samples_names)\n",
    "print(test_samples_names)"
   ],
   "metadata": {
    "id": "IseAHMeDkZP3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "samples = {}\n",
    "\n",
    "with open('00sequences.txt', 'r') as f:\n",
    "  lines = f.readlines()\n",
    "  lines = lines[21:]\n",
    "  for line in lines:\n",
    "    # print(repr(line))\n",
    "    line = line.replace(\"\\t\\tframes\\t\", \",\")\n",
    "    line = line.replace(\"\\tframes\\t\", \",\")\n",
    "    # print(repr(line))\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    # print(repr(line))\n",
    "    line_split = line.split(',')\n",
    "\n",
    "    if len(line_split) == 1 and line_split[0] == '':\n",
    "      continue\n",
    "\n",
    "    line_split = list(map(lambda x: x.strip(), line_split))\n",
    "\n",
    "    # print(line_split)\n",
    "    # after all this processing, line_split looks like:\n",
    "    # ['person01_boxing_d1', '1-95', '96-185', '186-245', '246-360']\n",
    "\n",
    "    video_name = line_split[0]\n",
    "\n",
    "    # process video_frames\n",
    "    samples[video_name] = [list(map(int, video_frames.split('-'))) for video_frames in line_split[1:]] # skip video_name\n",
    "\n",
    "    # example entry in samples looks like:\n",
    "    # {'person01_boxing_d1': [[1, 95], [96, 185], [186, 245], [246, 360]]}"
   ],
   "metadata": {
    "id": "roT-PL35k-aX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "label_map = {\n",
    "    \"walking\": 0,\n",
    "    \"jogging\": 1,\n",
    "    \"running\": 2,\n",
    "    \"boxing\": 3,\n",
    "    \"handwaving\": 4,\n",
    "    \"handclapping\": 5\n",
    "}\n",
    "\n",
    "def build_dataset(sample_names, max_frames):\n",
    "  data_samples = []\n",
    "  labels = []\n",
    "\n",
    "  for sample_name in sample_names:\n",
    "\n",
    "    if sample_name == 'person13_handclapping_d3':\n",
    "      continue\n",
    "\n",
    "    # open the video\n",
    "    cap = cv2.VideoCapture(f'data/{sample_name}_uncomp.avi')\n",
    "\n",
    "    # Check if the video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video file: {sample_name}\")\n",
    "\n",
    "    # Read frames and store them\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    # release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # get the list of frames for each subvideo\n",
    "    subset_video_frames = samples[sample_name] # samples is a global object\n",
    "\n",
    "    for subset_video in subset_video_frames:\n",
    "      subset_video_list = frames[subset_video[0]-1:subset_video[1]-1]\n",
    "\n",
    "      # uniform frame count\n",
    "      if len(subset_video_list) >= max_frames:\n",
    "          indices = np.linspace(0, len(subset_video_list) - 1, num=max_frames, dtype=int) # sample frames\n",
    "          capped_subset_video_list = [subset_video_list[i] for i in indices]\n",
    "      else:\n",
    "          # Pad with black frames if too short\n",
    "          pad_count = max_frames - len(subset_video_list)\n",
    "          capped_subset_video_list = subset_video_list + ([np.zeros((120, 160, 3), dtype=np.uint8)] * pad_count)\n",
    "\n",
    "      # convert to np array\n",
    "      subset_video_array = np.array(capped_subset_video_list)\n",
    "\n",
    "      # add the data\n",
    "      data_samples.append(subset_video_array)\n",
    "\n",
    "      # add the label\n",
    "      labels.append(label_map[sample_name.split('_')[1]])\n",
    "\n",
    "  return data_samples, labels"
   ],
   "metadata": {
    "id": "OAUe9f2SrilS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import os\n\n# Use MAX_FRAMES from configuration cell\nsave_dir = os.path.join(DATA_DIR, 'KTHActions', str(MAX_FRAMES))\nos.makedirs(save_dir, exist_ok=True)",
   "metadata": {
    "id": "mEIEfKIgWHcn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "training_data, training_labels = build_dataset(train_samples_names, MAX_FRAMES)\n",
    "print(len(training_data))\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "np.save(os.path.join(save_dir, f'kthactions_training_{MAX_FRAMES}.npy'), training_data)\n",
    "np.save(os.path.join(save_dir, f'kthactions_training_labels_{MAX_FRAMES}.npy'), training_labels)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mX-r-YLt0VL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756276701327,
     "user_tz": 300,
     "elapsed": 13621,
     "user": {
      "displayName": "Sam Sasaki",
      "userId": "14262134318359374727"
     }
    },
    "outputId": "9ea639cf-6aec-46f6-b224-d45a4dc12493"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "760\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "val_data, val_labels = build_dataset(val_samples_names, MAX_FRAMES)\n",
    "print(len(val_data))\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels)\n",
    "np.save(os.path.join(save_dir, f'kthactions_val_{MAX_FRAMES}.npy'), val_data)\n",
    "np.save(os.path.join(save_dir, f'kthactions_val_labels_{MAX_FRAMES}.npy'), val_labels)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-7nCkzNai3l",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756276710252,
     "user_tz": 300,
     "elapsed": 8922,
     "user": {
      "displayName": "Sam Sasaki",
      "userId": "14262134318359374727"
     }
    },
    "outputId": "ddf9dea0-b6a5-4322-e175-7a0500cc46dc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "768\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data, test_labels = build_dataset(test_samples_names, MAX_FRAMES)\n",
    "print(len(test_data))\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "np.save(os.path.join(save_dir, f'kthactions_test_{MAX_FRAMES}.npy'), test_data)\n",
    "np.save(os.path.join(save_dir, f'kthactions_test_labels_{MAX_FRAMES}.npy'), test_labels)"
   ],
   "metadata": {
    "id": "RziWf039aoKX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1756276721101,
     "user_tz": 300,
     "elapsed": 10848,
     "user": {
      "displayName": "Sam Sasaki",
      "userId": "14262134318359374727"
     }
    },
    "outputId": "7b3a6999-92f2-4012-8f4e-3f3bdcbf92ac"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "863\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalized"
   ],
   "metadata": {
    "id": "BQ6hNRitW7mR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# training\n",
    "normalized_training_data = training_data / 255\n",
    "np.save(os.path.join(save_dir, f'kthactions_normalized_training_{MAX_FRAMES}.npy'), normalized_training_data)\n",
    "\n",
    "# validation\n",
    "normalized_val_data = val_data / 255\n",
    "np.save(os.path.join(save_dir, f'kthactions_normalized_val_{MAX_FRAMES}.npy'), normalized_val_data)\n",
    "\n",
    "# testing\n",
    "normalized_test_data = test_data / 255\n",
    "np.save(os.path.join(save_dir, f'kthactions_normalized_test_{MAX_FRAMES}.npy'), normalized_test_data)"
   ],
   "metadata": {
    "id": "o9LF1T_WW8yF"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}